# Galileo configuration
GALILEO_API_KEY=

# OpenAI configuration
# Use "_dummy_" in OPENAI_API_KEY to use Ollama instead of OpenAI
OPENAI_API_KEY=your_dummy_api_key

# Ollama configuration (used when OPENAI_API_KEY contains "_dummy_")
OLLAMA_MODEL=gpt-oss:20b
OLLAMA_BASE_URL=http://localhost:11434/v1

# OpenAI model (used when OPENAI_API_KEY does not contain "_dummy_")
OPENAI_MODEL=gpt-4o-mini
